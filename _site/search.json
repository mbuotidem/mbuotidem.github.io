[
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "mbuotidem.github.io",
    "section": "",
    "text": "MIT License\nCopyright (c) 2018 Nicolas Vanhoren\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/2021-04-25-building-a-modern-web-application-using-aws-cdk-part-4.html",
    "href": "posts/2021-04-25-building-a-modern-web-application-using-aws-cdk-part-4.html",
    "title": "Part 4 - Guichet - Building the transcription capability",
    "section": "",
    "text": "In our last post we built out the s3 bucket, DynamoDB table and lambda function resources for our application. In this post, we will modify the placeholder lambda function that we created. At the end of the post, we should be able to upload a sound file into our bucket and have our lambda invoke the Amazon Transcribe service with it.\n\nWorking with Amazon Transcribe\nCreating an S3 bucket resource is simple with the AWS CDK. The same general pattern applies regardless of the construct. All you need do is import the module that contains said construct, and then make use of it. In this case, we need the s3 construct which we can find in the npm module @aws-cdk/aws-s3. Our code below does just that in addition to setting some bucket properties such as the bucket’s removal policy and the access permissions. You can learn more about these bucket property options here. Finally, we use the CfnOutput construct to surface the name of the created bucket upon completion.\nimport * as cdk from '@aws-cdk/core';\nimport * as s3 from '@aws-cdk/aws-s3';\n\n//s3 audio bucket\nconst audioBucket = new s3.Bucket(this, 'AudioBucket', {\n    removalPolicy: cdk.RemovalPolicy.DESTROY,\n    publicReadAccess: true,\n    accessControl: s3.BucketAccessControl.PUBLIC_READ,\n});\n\nnew cdk.CfnOutput(this, 'audioBucket', { value: audioBucket.bucketName });\n\nLiking the series? In our next post, we will continue building out our lambda function, adding the ability to store the transcription results in a DynamoDB table. You can find the previous post here And if you’d like to dive into the code, here is a link to the project on GitHub."
  },
  {
    "objectID": "posts/2021-01-09-how-to-hot-reload-auto-refresh-react-app-on-WSL.html",
    "href": "posts/2021-01-09-how-to-hot-reload-auto-refresh-react-app-on-WSL.html",
    "title": "mbuotidem.github.io",
    "section": "",
    "text": "If you’re working on a React app on Windows using Windows Subsystem for Linux (WSL), you might find that your app does not reflect your changes on save.\nYour first step to fixing this is to ensure that your React files are located on the WSL filesystem and not the Windows filesystem. For example, if your files are saved at :\nC:Users\\yourusername\\Documents\\test-react-app\nUse the cp command to copy them over to your WSL filesystem like so:\ncp -r /mnt/c/Users/yourusername/Documents/test-react-app ~/test-react-app.\nThe above will copy the files to your WSL user account’s home directory which you can always get to by typing wsl ~ from Command Prompt or Windows Terminal.\nIf that still does not work, try running your app in the terminal by prepending the commands below to npm start For example:\nCHOKIDAR_USEPOLLING=true npm start\nThere is a chance that it still won’t auto-reload. In that case, try running your app with:\nFAST_REFRESH=false npm start.\nFor whichever of these that works, you you might want to make it into a more permanent solution instead of having to type that in each time. To do that, you have two options.\n\nYou can create a .env file in your project directory if you don’t already have one and add\nCHOKIDAR_USEPOLLING=true\nFAST_REFRESH=false\n\nto the .env file.\n\nOr you can edit your package.json file like so:\n{\n\n  \"scripts\": {\n    \"start\": \"FAST_REFRESH=false react-scripts start\",\n    \"build\": \"react-scripts build\",\n    \"test\": \"react-scripts test\",\n    \"eject\": \"react-scripts eject\"\n  },\n\n\n}\n\nCredit : https://stackoverflow.com/a/56199112{:class=“lnk”}"
  },
  {
    "objectID": "posts/2021-01-08-how-to-view-issues-commented-on-github.html",
    "href": "posts/2021-01-08-how-to-view-issues-commented-on-github.html",
    "title": "mbuotidem.github.io",
    "section": "",
    "text": "Have you ever wanted to check back on a GitHub issue you made a comment on? I recently needed to and floundered about on the UI trying to find a link or button that would help me do that. Ultimately, I was unsuccessful and had to turn to Google. Here’s how to do it courtesy of the the lovely folks at stackexchange.\n\nMake sure you’re logged in and then enter the url\nhttps://github.com/notifications/subscriptions?commenter={yourusername}\n\nSo in my case, that would be :\nhttps://github.com/notifications/subscriptions?commenter=mbuotidem"
  },
  {
    "objectID": "posts/2021-01-17-how-to-get-free-or-discounted-microsoft-azure-certifications.html",
    "href": "posts/2021-01-17-how-to-get-free-or-discounted-microsoft-azure-certifications.html",
    "title": "mbuotidem.github.io",
    "section": "",
    "text": "The new year often brings with it resolutions. If you’re in tech, that might take the form of get a professional certification. If this is you and you’d like to do so without breaking the bank, here are some ideas for getting free or discounted certifications.\nOne way to obtain certiications is to attend events sponsored by the cloud provider. These include industry conferences like Microsoft Build which is actually how I got my first free exam voucher. I’d attended Build last year and participated in the Cloud Skills Challenge and was therefore eligible for a free certification. However, I’d completely forgotten about it until I got a reminder email from Microsoft that my free certification voucher was expiring. (BTW, I got this reminder email 21 days to the expiry date so don’t be like me and set your own reminder - 21 days might not be enough time to prepare for the cert you want!)\n{:class=“img-responsive”}\nAnd just like that, I am now signed up to take the AZ-900 Azure Fundamentals exam at the end of this month. Blog post incoming on my approach to preparing for this.\nBut what happens after AZ-900? How do I get more discounted certification vouchers? The answer is attend more Microsoft Events and take on more Microsoft Skills Challenges!\nMicrosoft offers Virtual Training Days where devs and IT professionals can learn more about their offerings. Many of these events will tell you in the description if there is a certification offer as in the image below:\n{:class=“img-responsive”}\nYour other option is to sign up and participate in Microsoft Cloud Skills Challenge - 30 Days to Learn It. As the name implies, you sign up to take a challenge to prepare for a specific Microsoft certification in 30 days. If you complete your training, you become eligible for 50 percent off the cost of the certification. Caveat: you can only get a discounted certification code once every 6 months. So what are you waiting for?! Go sign-up already so that you can snag two discounted certifications this year! You’ve got this!"
  },
  {
    "objectID": "posts/2021-01-20-how-I-studied-for-AZ-900-microsoft-azure-fundamentals-exam.html",
    "href": "posts/2021-01-20-how-I-studied-for-AZ-900-microsoft-azure-fundamentals-exam.html",
    "title": "mbuotidem.github.io",
    "section": "",
    "text": "I just passed the AZ-900: Microsoft Azure Fundamentals exam and I wanted to add some quick notes on the resources I used to prepare for it. Before I go on to do that, if you haven’t already, check out my post on how to score a free or discounted Azure certification exam.\n\n\n\n\n\n\nOkay, back to the topic on hand, AZ-900. AZ-900 is a beginner level Azure exam and if you’ve used the Azure Portal to develop cloud applications, as was my case, passing it really does not require extensive preparation. All I used was the official training available from Microsoft Learn. The learning paths available here come with built-in free labs and links to Microsoft Documentation on the various Azure services discussed. The labs are a pretty nifty feature but not every service is accessible via them. For access to those services, consider signing up for a free Azure account.\nIf you don’t have much experience with the Azure Portal, I would recommend supplementing Microsoft Learn and the Microsoft Docs the various modules refer you to with some sort of course. For all things Microsoft, I lean towards Pluralsight. They do have an AZ-900 learning path If I had absolutely no Azure knowledge, this would have been my starting point.\nNext up, AZ-204."
  },
  {
    "objectID": "posts/2021-01-31-how-I-studied-for-CLFC01-AWS-Certified-Cloud-Practitioner-AWS-CCP-Exam.html",
    "href": "posts/2021-01-31-how-I-studied-for-CLFC01-AWS-Certified-Cloud-Practitioner-AWS-CCP-Exam.html",
    "title": "mbuotidem.github.io",
    "section": "",
    "text": "I just passed the CLF-C01 AWS Certified Cloud Practitioner Exam (AWS CCP) and like I did for the AZ-900: Microsoft Azure Fundamentals exam, I wanted to add some quick notes on the resources I used to prepare for it.\n\n\n\n\n\n\nBefore I continue, a note on cloud certifications and their value or lack of. For some reason, these certifications do seem attractive to some recruiters. This is perhaps because if nothing else, they indicate an individuals willingness to self-study and learn skills independently. However, if the ultimate goal is bolster ones hireability, I would not recommend pursuing these certifications without putting in the time to also truly use the services to build and deploy real applications. The winning combination for these certifications is having them in addition to work experience using the cloud services whether through an internship, volunteer position, or full-time job. If you don’t have any of those, then personal projects on GitHub that demonstrate their usage could stand in. Only then can one speak convincingly about the services and how they employed them to solve real-world problems.\nOkay, now to the meat of the discussion. The AWS CCP is a beginner level AWS exam and although it has questionable value for a developer, I decided to take it anyway because doing so allows you to earn a 50% discount on a subsequent AWS Exam. I have my eyes on the AWS Certified Developer Associate, (DVA-C01) so getting this discount makes sense. This was especially important as I couldn’t find any other way to get a discount for AWS exams unlike is the case with Microsoft Azure certifications.\nI prepped for this exam in a week using the following resources:\n\nAWS Cloud Practitioner Essentials course available on Coursera.\nAWS Cloud Practitioner Learning Path on Pluralsight\nThe Official AWS Services Overview Whitepaper\n\nIf you don’t have much experience with the AWS, I would recommend supplementing the above with this free course courtesy of freeCodeCamp.\nNext up, DVA-C01."
  },
  {
    "objectID": "posts/2021-04-23-building-a-modern-web-application-using-aws-cdk-part-2.html",
    "href": "posts/2021-04-23-building-a-modern-web-application-using-aws-cdk-part-2.html",
    "title": "Part 2 - Guichet - Building the CI/CD pipeline",
    "section": "",
    "text": "The last post in this series discussed our proposed architecture for our CI/CD pipeline. In this post, we shall build the actual CI/CD pipeline using the AWS CDK. But first, a crash course on CDK terminology.\nA construct in CDK world refers to a cloud component. This can be a single resource like an Amazon S3 bucket, or it can be a grouping of several resources such as an S3 bucket connected to a lambda.\nA stack is a unit of deployment. It follows the same rules as a CloudFormation stack and is made up of one or more constructs. For example, we can place both a single Amazon S3 bucket and/or an S3 bucket connected to a lambda in a stack.\nAn app is your final cloud application - what gets deployed. It can contain one or more Stacks and it’s what gets synthesized into a CloudFormation template. The synthesized template is what the CloudFormation service will then use to provision the cloud resources that you defined.\n\nOur Approach\nWe will create 2 stacks. First, we will create the application stack. For this iteration, the application will have just a simple placeholder lambda. Next, we will create a pipeline stack based on the CDK Pipelines construct. This pipeline stack will be responsible for getting our source code, building it, and deploying the application stack. The CDK Pipelines construct will get provisioned first, and then it will ensure that our application stack gets deployed.\nAfter both stacks have been successfully deployed, When we commit a change to the repo, the pipeline stack will first update itself (known as a self-mutation) as needed, and then it will redeploy the application.\nNote that this means that both the code for our application stack, and the code for the pipeline stack will live in the same repo. This setup means that we can easily change both our core application and our pipeline. For example, initially, we shall only have our application deployed to our development environment. In the future, we could then add a step for the application to be deployed to a production environment. The CDK Pipelines construct will do the heavy lifting of ensuring that all this works seamlessly.\n\n\nThe application stack\nAs mentioned earlier, we will start with just a single construct in our application stack, an AWS Lambda function. We will also export the name of said lambda function as an output. Below is the code:\nimport * as cdk from '@aws-cdk/core';\nimport * as lambda from '@aws-cdk/aws-lambda';\n\n\nexport class GuichetStack extends cdk.Stack {\n\n    public readonly lambdaName: cdk.CfnOutput;\n\n    constructor(scope: cdk.Construct, id: string, props?: cdk.StackProps) {\n        super(scope, id, props);\n\n        const transcriber = new lambda.Function(this, 'Transcriber', {\n            runtime: lambda.Runtime.NODEJS_10_X,\n            code: lambda.Code.fromAsset('lambda'),\n            handler: 'transcriber.handler'\n        });\n\n\n        this.lambdaName = new cdk.CfnOutput(this, 'TranscriberLambdaName', {\n            value: transcriber.functionName\n        });\n    }\n}\n\nThis class, GuichetStack, is a construct, our very own construct that we’ve composed atop the in-built lambda function construct from the AWS CDK. We create a readonly property, lambdaName, which we will use to output the name of the lambda that gets created. The AWS CDK will auto-generate a name for the lambda and so if we want to know that name without going to search for it in the GUI page for Lambda, making it a cdk.CfnOutput is wise.\nWe then create our lambda resource which we store in the variable transcriber. Notice how the AWS CDK lets us set up important attributes for our lambda such as the desired runtime and the name of the handler. We also tell it where the lambda code, reproduced below, can be found. We do that with code: lambda.Code.fromAsset('lambda') which says “Hey CDK, in this directory, there’s a folder called lambda that contains the code for the lambda”.\nexports.handler = async function (event) {\n    console.log(\"request:\", JSON.stringify(event, undefined, 2));\n    return {\n        statusCode: 200,\n        headers: { \"Content-Type\": \"text/plain\" },\n        body: `Hello! You've hit Guichet at ${event.path}\\n`\n    };\n};\n\nFor now, we are just returning a simple string response to test that the lambda works. In later posts, we will build out the transcription logic. During the synthesis step, this lambda function will be packaged up and added to the CloudFormation stack that the AWS CDK will generate for us.\n\n\nTesting the application stack\nSince our infrastructure is code, we should treat it just the same way we would treat our application code and that includes having tests. Testing AWS CDK constructs is fairly easy. The CDK team has provided the CDK assert module which comes with helpers that simplify testing CDK code. This module relies on the Jest test framework.\nOne of the helpers provided is the toHaveResource function. It allows you to check that a resource of a particular type exists(it does not evaluate logical identifiers), and that some properties are set to specific values. We use the toHaveResource helper here to verify that our application stack does indeed contain an AWS Lambda function with our desired runtime. Below is the test code:\nimport '@aws-cdk/assert/jest';\nimport { App } from '@aws-cdk/core';\nimport { GuichetStack } from '../src/guichet';\n\ndescribe('Create Guichet App Resources', () => {\n    describe('GuichetStack', () => {\n        const app = new App({ context: { '@aws-cdk/core:newStyleStackSynthesis': '1' } });\n\n        describe('has', () => {\n\n            let stack = new GuichetStack(app, 'test', {\n            });\n\n\n            test('Lambda exists', () => {\n                expect(stack).toHaveResource(\"AWS::Lambda::Function\", {\n                    Runtime: \"nodejs10.x\"\n\n                });\n            });\n        });\n    });\n});\n\nAnd here are the test results:\n{:class=“img-responsive”}\n\n\nThe CDK Pipeline Stack\nBefore we create the pipeline itself, let us setup a pipeline stage. A stage represents a logical phase of the deployment. The code below, in the class GuichetPipelineStage, is our stage. We will later add it to our pipeline using pipeline.addApplicationStage() and passing it an instance. If we do not perform this step of adding an application stage, then we’d have a functional pipeline, albeit one that doesn’t build our application.\nimport { GuichetStack } from './guichet';\nimport { Stage, CfnOutput, Construct, StageProps } from '@aws-cdk/core';\n\nexport class GuichetPipelineStage extends Stage {\n    public readonly lambdaName: CfnOutput;\n\n    constructor(scope: Construct, id: string, props?: StageProps) {\n        super(scope, id, props);\n\n        const service = new GuichetStack(this, 'Guichet');\n\n        this.lambdaName = service.lambdaName;\n\n    }\n}\n\nWe pull in our GuichetStack construct from the application stack section above. We also pull in some necessary constructs from @aws-cdk/core. We subclass the pre-definedStage construct which knows how to play nice with the CDK Pipeline construct. Th en we add a readonly property lambdaName so that we can surface the lambdaName property from our GuichetStack construct. We then instantiate our GuichetStack and finally set the lambdaName property to whatever is returned from GuichetStack.\nSo now that our stage is all ready, the moment we’ve been building up to is here. Behold, our CDK Pipeline stack:\nimport { App, Construct, Stack, StackProps, SecretValue } from '@aws-cdk/core';\nimport * as codepipeline from '@aws-cdk/aws-codepipeline';\nimport * as codepipeline_actions from '@aws-cdk/aws-codepipeline-actions';\nimport { SimpleSynthAction, CdkPipeline } from \"@aws-cdk/pipelines\";\nimport { StringParameter } from '@aws-cdk/aws-ssm';\nimport { GuichetPipelineStage } from './pipeline-stage';\n\nexport class GuichetPipelineStack extends Stack {\n  constructor(scope: Construct, id: string, props: StackProps = {}) {\n    super(scope, id, props);\n\n    // define resources here...\n\n    const sourceArtifact = new codepipeline.Artifact();\n    const cloudAssemblyArtifact = new codepipeline.Artifact();\n\n    const githubOwner = StringParameter.fromStringParameterAttributes(this, 'gitOwner', {\n      parameterName: 'guichet-repo-owner'\n    }).stringValue;\n\n    const githubRepo = StringParameter.fromStringParameterAttributes(this, 'gitRepo', {\n      parameterName: 'guichet-repo'\n    }).stringValue;\n\n    const githubBranch = StringParameter.fromStringParameterAttributes(this, 'gitBranch', {\n      parameterName: 'guichet-repo-branch'\n    }).stringValue;\n\n    const pipeline = new CdkPipeline(this, 'Pipeline', {\n      crossAccountKeys: false,\n      cloudAssemblyArtifact,\n      // Define application source\n      sourceAction: new codepipeline_actions.GitHubSourceAction({\n        actionName: 'GitHub',\n        output: sourceArtifact,\n        oauthToken: SecretValue.secretsManager('guichet-repo-git-token', { jsonField: 'guichet-repo-git-token' }), // this token is stored in Secret Manager\n        owner: githubOwner,\n        repo: githubRepo,\n        branch: githubBranch\n      }),\n      // Define build and synth commands\n      synthAction: SimpleSynthAction.standardNpmSynth({\n        sourceArtifact,\n        cloudAssemblyArtifact,\n        installCommand: 'npm i -g npm && npm i -g aws-cdk@1.95.2 && npm install',\n        synthCommand: 'npx cdk synth'\n      })\n    });\n\n    pipeline.addApplicationStage(new GuichetPipelineStage(this, 'dev'));\n\n\n  }\n}\n\n// for development, use account/region from cdk cli\nconst devEnv = {\n  account: process.env.CDK_DEFAULT_ACCOUNT,\n  region: process.env.CDK_DEFAULT_REGION,\n};\n\nconst app = new App();\n\nnew GuichetPipelineStack(app, 'GuichetPipelineDev', { env: devEnv });\n// new GuichetPipelineStack(app, 'GuichetPipelineProd', { env: prodEnv });\n\nThe code above does several things.\nsourceArtifact/cloudAssemblyArtifact: These will store our source code and cloud assembly respectively. A cloud assembly refers to the files that include everything needed to deploy your app to a cloud environment. For example, it could include an AWS CloudFormation template for each stack in your app, and a copy of any file assets (such as our lambda code) that you reference in your app.\nconst x = StringParameter.fromStringParameterAttributes(...): Here we are following a 12 factor app best practice of strict separation of config from code. We store the information regarding the source code repository in a Secrets Manager parameter so that it can be altered without changing the code. This allows us to meet the litmus test that the codebase can be open-sourced at any moment without compromising any credentials.\nconst pipeline = new CdkPipeline(...): This initializes the pipeline with the required values. This will serve as the base component moving forward. Every pipeline requires at bare minimum:\n\nCodeCommitSourceAction(...): The sourceAction of the pipeline will check the designated repository for source code and generate an artifact.\nSimpleSynthAction.standardNpmSynth: The synthAction of the pipeline will take the source artifact generated in by the sourceAction and build the application based on the buildCommand. This is always followed by npx cdk synth\n\npipeline.addApplicationStage(new GuichetPipelineStage(this, 'dev'));: This is where we add the pipeline stage that will deploy our application stack. As alluded to earlier, all we had up to this point was a fully functional pipeline that could run and self-mutate, but would not deploy our application. Adding the stage tells the pipeline “After you’re done grabbing the source code and self-mutating, lay the framework for the deployment of the application stack contained in the stage”.\nnew GuichetPipelineStack(app, 'GuichetPipelineDev', { env: devEnv });: Finally we attach our pipeline stack to a CDK App construct. The app gets synthesized into the CloudFormation template that will provision our cloud resources. The cool part of this is that if we wanted to provision this pipeline and the application it builds in another environment, all we’d need to do is add another similar line and then provide the environment information and then CDK will do it for us. For example, new GuichetPipelineStack(app, 'GuichetPipelineProd', { env: prodEnv });, would deploy GuichetPipelineStack in our production environment, provided the variable prodEnv contains the account and region number for said production environment.\n\n\nTesting the CDK Pipeline Stack\nWhen testing the application stack above, we used the toHaveResource helper. To test the pipeline stack, we shall use both that and the toCountResources helper. The toCountResources helper checks that n number of resources of a particular type exist, with or without specific properties. Here is our test code:\nimport { arrayWith, objectLike } from '@aws-cdk/assert';\nimport '@aws-cdk/assert/jest';\nimport { App } from '@aws-cdk/core';\nimport { GuichetPipelineStack } from '../src/main';\n\n\n\ndescribe('Create Pipeline', () => {\n  describe('GuichetPipeline', () => {\n    const app = new App({ context: { '@aws-cdk/core:newStyleStackSynthesis': '1' } });\n\n    describe('has', () => {\n\n      let stack = new GuichetPipelineStack(app, 'test', {\n      });\n\n      test('Pipeline IAM roleS', () => {\n        expect(stack).toCountResources('AWS::IAM::Role', 6);\n\n      });\n\n      test('Pipeline config', () => {\n        expect(stack).toHaveResource('AWS::CodePipeline::Pipeline',\n          {\n            Stages: arrayWith({\n              Name: 'Source',\n              Actions: arrayWith(\n                objectLike({\n                  ActionTypeId: objectLike({}),\n                  Configuration: objectLike({\n                    Owner: objectLike({}),\n                    Repo: objectLike({}),\n                    Branch: objectLike({}),\n                    OAuthToken: \"{{resolve:secretsmanager:guichet-repo-git-token:SecretString:guichet-repo-git-token::}}\",\n                    PollForSourceChanges: false\n                  }),\n                  Name: 'GitHub',\n                  OutputArtifacts: arrayWith(\n                    objectLike({\n\n                    })),\n                  RunOrder: 1,\n\n                })\n              )\n            })\n          });\n      });\n\n      test('dev stage', () => {\n        expect(stack).toHaveResource('AWS::CodePipeline::Pipeline',\n          {\n            Stages: arrayWith({\n              Name: 'dev',\n              Actions: arrayWith(\n                objectLike({\n\n                })\n              )\n            })\n          });\n      });\n\n      test('1 pipeline resource', () => {\n        expect(stack).toCountResources('AWS::CodePipeline::Pipeline', 1);\n\n      });\n\n      test('CodeBuild project', () => {\n        expect(stack).toHaveResource('AWS::CodeBuild::Project');\n\n      });\n\n    });\n  });\n});\n\nOur first test ‘Pipeline IAM roles’ uses the ‘countResources’ to check for the existence of 6 IAM Roles which is the number of roles our pipeline currently needs to perform its tasks.\nTest ‘Pipeline config’ tests that our pipeline has the right configuration to talk to our GitHub repo, i.e an owner, a repo, a branch, and a reference to the oauth personal access token secret.\nTest ‘dev stage’ checks to ensure that our application stage, i.e the stage in which our application code is built, was added to the pipeline.\nTest ‘1 pipeline resource’ verifies that our pipeline stack has a pipeline resource.\nAnd finally, test ‘Codebuild project’ checks that our pipeline stack has a codebuild project which is what will build our cloud assemblies.\nBelow is the result of the test run :\n{:class=“img-responsive”}\n\nLiking the series? In our next post, we will continue building out our backend, adding the S3 Bucket where our audio files will be stored, the DynamoDB table where the transcriptions will be saved, and all plumbing and required permissions for our lambda to interact with both resources. You can find the previous post here And if you’d like to dive into the code, here is a link to the project on GitHub."
  },
  {
    "objectID": "posts/2021-05-28-111-connection-refused-while-connecting-to-upstream-net-core-elastic-beanstalk.html",
    "href": "posts/2021-05-28-111-connection-refused-while-connecting-to-upstream-net-core-elastic-beanstalk.html",
    "title": "Elastic Beanstalk 502 Bad Gateway / 111 connection refused while connecting to upstream error on .net",
    "section": "",
    "text": "I recently tried to host a .NET web application on Elastic Beanstalk. I was using the AWS Toolkit for Visual Studio to handle the deployment so I thought everything would just go swimmingly. Initially, it seemed I was right - the application deployed successfully and the Elastic Beanstalk info page told me that the Environment was healthy. Nice. And then I clicked the url and I saw this lovely page:\n{:class=“img-responsive”}\nSo off to Google to figure out what’s wrong and sure enough, there were a couple of stackoverflow questions from users who had encountered this 502 Bad Gateway error so things were looking hopeful. However, after trying a couple of suggestions from some of the stackoverflow results, it became clear that even though my error was the same, the root cause of the problem was definitely different from what was causing the issues for other users.\nSo back to Google I went, this time, hoping for a blog post from some amazing developer who had encountered my problem before and could shed some light. I found this post by Martin Beebs Elastic Beanstalk 502 Bad Gateway. He was helping troubleshoot another dev’s issues with deploying a .net core application using the AWS Visual Studio Toolkit which was exactly what I was trying to do.\nThe gist of Martin’s blog post was that when you deploy a .net core web application to Elastic Beanstalk, it saves the logs from your webserver to the file web.stdout. You can access these logs by using the Elastic Beanstalk Console to download the full logs for your environment which you will get as a zip file with a filename like BundleLogs-123456789112. Extract said zip and go to /var/log/ and ideally, you should find the web.stdout file. Ideally, you should also find the error that your application’s webserver is experiencing that’s leading to the 502 Bad Gateway error in this file.\nArmed with that knowledge, I went and got my logs from the Elastic Beanstalk console and then went looking for my web.stdout file and there was no such log file. What I did have though in /var/log/nginx/ was the logs from Nginx which showed me the error 111-connection-refused-while-connecting-to-upstream, client: 12.345.678.910, server: , request: \"GET / HTTP/1.1\", upstream: \"http://127.0.0.1:5000/\", host: \"pt-dev.us-east-1.elasticbeanstalk.com\" Searching for that error indicated that it could happen if your webserver wasn’t even getting started. At this point, I knew that cowboy coding was not going to hack it anymore, I had to go consult the AWS documentation, and maybe even do a walkthrough.\nBut first, I decided to eliminate my worry that perhaps my application just wasn’t working on Elastic Beanstalk because I developed it on a Windows machine and I was trying to deploy it to a .net core Amazon Linux container. .NET core is cross-platform so this shouldn’t be a valid concern, but hey, you never know, let’s just make sure. Fortunately, the code was already on GitHub and I had access to the GitHub Codespaces beta, so I launched a Codespace from the repo and ran the application and it worked there. So with that test, I knew that the application could run on a Linux box. So the problem likely was that there was some configuration I had to make in Elastic Beanstalk to tell it to run my application dll and where to find said dll. My assumption had been that the AWS Toolkit for Visual Studio would handle this for me but clearly, either it didn’t, or it had set it up wrong.\nSo back to troubleshooting on Elastic Beanstalk. I went back to the AWS documentation and I started reading everything under the section Working with .NET Core on Linux. Eventually, I got to the page Using a Procfile to configure your .NET Core on Linux environment. It turns out, this is exactly where I can tell Elastic Beanstalk which applications I want it to run. Below is an example Procfile:\nweb: dotnet ./dotnet-core-app1/dotnetcoreapp1.dll\nweb2: dotnet ./dotnet-core-app2/dotnetcoreapp2.dll\nBefore going ahead to create my own Procfile, I decided to check if it was indeed true that the AWS Toolkit was not creating my Procfile. So I headed to the Elastic Beanstalk console and went to the Application versions page for my application. There I downloaded the .net core publish zip file that Elastic Beanstalk had created. And there was a Procfile in there. So what was the problem? Here is what I had in my Procfile:\nweb: dotnet exec ./PeerTutor.IntegrationTests.dll\nThis means that instead of trying to run my web application, Elastic Beanstalk was trying to run the tests I had written for my application. I had several dotnet projects in my solution - my application, my application’s unit tests, and my application’s integration tests and I had them all setup to build in Configuration Manager as you can see in the screenshot below:\n{:class=“img-responsive”}\nFor some reason, the AWS Toolkit decided that the application dll that needed to be added to the Procfile was the integration test instead of the actual web application’s dll. So to solve this, all I had to do was uncheck the test projects in Configuration Manager, leaving only my web application. You can find Configuration Manager in Visual Studio 2019 by going to the Build menu item and it will be close to the bottom of the list - Build>Configuration Manager.\n{:class=“img-responsive”}\nAnd with that change, I rebuilt my application. Then I ran the AWS Toolkit wizard again and this time, it correctly added the web application to the Procfile. My Procfile now looked like this :\nweb: dotnet exec ./PeerTutor.dll\nAnd sure enough, when I visited my application url, this time around, it was live and running. And yes, I checked out my Full Logs again and yup, I now had a web.stdout file in there with all the log messages from the webserver.\nWhat’s the moral of the story? I remember reading something on the AWS sub-reddit to the effect of “AWS documentation should be read as a book (read everything), and not as a quick consultation guide (stackoverflow post)”. This is definitely the case. If I had spent the time upfront to read the documentation, I’d have known about the Procfile earlier and possibly been on the path to the solution sooner.\nNext up, I’m going to try running this application on Elastic Beanstalk via Docker, and then, I’ll check out AWS’ new competitor to Heroku, AWS AppRunner. But this time around, I’ll be sure to go read the documentation first if I encounter any issues :)"
  },
  {
    "objectID": "posts/2021-04-18-building-a-modern-web-application-using-aws-cdk-part-0.html",
    "href": "posts/2021-04-18-building-a-modern-web-application-using-aws-cdk-part-0.html",
    "title": "Part 0 - Guichet - a cloud native web application built on AWS using the CDK",
    "section": "",
    "text": "As part of my quest to become a cloud savvy software engineer, I recently took and passed the AWS Certified Developer Associate (DVA-C01) exam. While having the certification is nice, I’d also like to demonstrate my understanding of building applications on AWS with a real world project. As such, I will be building a cloud native serverless web application on AWS called Guichet.\nGuichet is a French word that denotes a grill opening, a small opening in the wall such as one you’d fine in a post office or cinema ticket window. It can also mean a counter, like one you’d find in a bank or again, a post office. It is this second meaning that hews to what I envision for the app, a one-stop location for world language teachers to issue and accept homework assignments, grade them, and perform several other language pedagogy related tasks. This is the long term vision for Guichet. In the short term however, I shall be focusing on a tiny slice of the desired functionality, namely, the ability to have students create audio recordings based on provided texts, and then view the transcriptions of said recordings side by side with the sample text in order to gauge their pronunciation ability."
  },
  {
    "objectID": "posts/2021-04-18-building-a-modern-web-application-using-aws-cdk-part-0.html#architecture-diagram",
    "href": "posts/2021-04-18-building-a-modern-web-application-using-aws-cdk-part-0.html#architecture-diagram",
    "title": "Part 0 - Guichet - a cloud native web application built on AWS using the CDK",
    "section": "Architecture Diagram",
    "text": "Architecture Diagram\nBelow is an initial architecture diagram. The application will have a React front-end. This front-end will live in an Amazon S3 bucket and will authenticate users with Amazon Cognito. Signed in users can then make an audio recording which will be stored in a different Amazon S3 bucket. Upon storage of the recording, the metadata will be placed on an Amazon SQS queue. The queue will trigger an AWS Lambda which will perform the transcription using Amazon Transcribe and then store the transcribed text in an Amazon DynamoDB table. Users will then be able to view the transcriptions via the React frontend which will call a different AWS Lambda fronted by an Amazon API Gateway.\n{:class=“img-responsive”}"
  },
  {
    "objectID": "posts/2021-04-18-building-a-modern-web-application-using-aws-cdk-part-0.html#architecture-decision-record",
    "href": "posts/2021-04-18-building-a-modern-web-application-using-aws-cdk-part-0.html#architecture-decision-record",
    "title": "Part 0 - Guichet - a cloud native web application built on AWS using the CDK",
    "section": "Architecture Decision Record",
    "text": "Architecture Decision Record\nReact: is the front-end for this project because React is a widely used and well supported library. As such, finding documentation or answers to thorny issues is likely to be easier.\nAmazon Cognito: Amazon Cognito provides user authentication, authorization and management. We will handle user authentication and authorization using Cognito because I am enticed by the idea of offloading a good chunk of the thorny job of login security to AWS. While I am aware that Cognito might have some serious kinks to work out, I think the benefits it promises might make it worth while.\nAmazon S3: Amazon S3 is an object storage service from Amazon. All sorts of files can be stored on S3 and various AWS services also use S3 as their backend data store. S3 also makes an excellent static site host which is all we need to host our React frontend . It also allows for future extensibility such as the use of AWS CloudFront as a content delivery network.\nAPI Gateway: API Gateway allows developers to create endpoints that when hit, can invoke or hand off work to various AWS services. We will be triggering one of our lambda’s through authenticated calls to API Gateway from our frontend. API Gateway works well for this purpose because it is tightly integrated with both Amazon Cognito and AWS Lambda. It also has very reasonable costs of operation.\nAWS Lambda: AWS Lambda allows you to run code in response to a variety of triggers. Your code can interact with both other AWS services and anything else you configure it to. Lambda’s do all of this without the developer having to worry about provisioning or running servers. This should result in huge cost savings both in development time and compute cost. In addition, Lambda’s tight integration with API Gateway which I alluded to earlier makes it a very versatile choice for handling the backend.\nAmazon DynamoDB: DynamoDB is a NoSQL key-value database offered by AWS. The data stored on DynamoDB is stored across AWS servers and fully managed by Amazon.DynamoDB is a perfect choice when one “has insufficient data for forecasting peaks and valleys in required database performance”. Given that this is a greenfield application, this is the exact situation we find ourselves in and thus, the choice to go with DynamoDB seems obvious.\nAmazon SQS: is a message queue service from AWS that we can use in distributed applications to exchange messages through a polling model. It’s value lies in its ability to decouple the sending of a message from the processing of said message. We will use SQS to trigger our second lambda which will be responsible for transcribing the audio and then storing the result in our DynamoDB table.\nAmazon Transcribe: Amazon Transcribe is a service form AWS that uses deep learning to perform automatic speech recognition. We choose it as our speech recognition service because of its low pricing and the fact that being part of the AWS ecosystem should make integration easier.\n\nDoes this sound intriguing to you? If so, stay tuned for the next post in the series where we shall begin working on our application’s CI/CD pipeline. And if you’d like to dive into the code, here is a link to the project on GitHub."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/2021-04-22-building-a-modern-web-application-using-aws-cdk-part-1.html",
    "href": "posts/2021-04-22-building-a-modern-web-application-using-aws-cdk-part-1.html",
    "title": "Part 1 - Guichet - CI/CD pipeline architecture",
    "section": "",
    "text": "The last post in this series discussed our proposed architecture and provided an architecture decision record. In this post, we shall lay the foundation for building out Guichet’s CI/CD pipeline. But what is a CI/CD pipeline?\n\nContinuous Integration, Continuous Deployment (CI/CD)\nCI/CD is generally accepted to mean, continuous integration (CI), and then either continuous deployment or continuous delivery (CD).\nContinuous integration is the use of a central repository to manage the software development process. Developers continually push their changes to this central repository and these changes are immediately built and tested.\nContinuous delivery is the process of deploying the built and tested code artifacts from the continuous integration step above to a test environment. This is to allow for further verification of the software. So for example if you ran unit tests during continuous integration, you might now run UI tests, speed and performance tests, and maybe load tests. When you are satisified that the software is fit for purpose, then you could click on an approval button that would trigger the deployment of the code to production.\nContinuous deployment is an optional step. Whereas in continuous delivery, the built and tested software requires a manual approval action before going to production, with continous deployment, you have such high confidence in your software and battery of verfication procedures that you let changes make their way up to production without explicit approval.\n\n\nThe CI/CD Pipeline\nA key component of CI/CD is the CI/CD pipeline. The pipeline refers to both the steps that must be performed in order to achieve CI/CD nirvana and the actual software infrastructure in use at each step. Components of a pipeline, also known as stages include:\n\nSource: You need somewhere to store the code that later parts of your pipeline will build and test. For Guichet, our source code repository will be GitHub. You can find the project on GitHub here.\nBuild: This is where the source code is compiled. We will be compiling our source code using Amazon’s CodeBuild offering.\nTest: Our tests will also be run on AWS CodeBuild.\nDeploy: We will use yet another AWS service, AWS CodeDeploy to handle the deployment of our code.\n\nYou can learn more about CI/CD pipelines here.\n\n\nThe Guichet CI/CD Pipeline\nOur CI/CD Pipeline will be built on AWS CodePipeline. AWS CodePipeline is a managed CI/CD service that integrates the aforementioned services, AWS CodeBuild and AWS CodeDeploy. It also performs other useful orchestrating functions including the task of getting our code from the source code repository, sending notification on success/failure etc.\nHere is an architecture diagram that shows you how our CI/CD pipeline will function:\n{:class=“img-responsive”}\nWe will write code and commit/push said code to GitHub. Our GitHub repository will have a webhook configured that will notify AWS CodePipeline of the recently pushed code. AWS CodePipeline will fetch the code and then send it of to AWS CodeBuild to build and test it. If the tests are successful, we will publish the compiled source code to an Amazon S3 bucket. AWS CodePipeline will then tell AWS CodeDeploy to go grab the compiled source code from the Amazon S3 bucket and deploy it. Since we will be using the AWS CDK (Cloud Development Kit), one of the artifacts in our Amazon S3 bucket will be the AWS CloudFormation templates that defines the needed infrastracture in the AWS Cloud.\nThe AWS CloudFormation service will read and process the template and stand up the resources defined therein.\n\n\nAWS CDK\nAt this point, a brief discussion of AWS CloudFormation and the AWS CDK would be helpful.\nAWS CloudFormation is a service that allows developers to model, provision, and manage cloud infractructure via templates. These templates are called CloudFormation templates and can be either YAML or JSON files. Using CloudFormation allows us to practice infrastructure-as-code, which is the idea that our infrastructure should be treated the same way we treat our application code, it should be stored in version control, undergo code review, and be both reliable and repeatable.\nUnfortunately, defining cloud infrastructure via text files can be a very difficult and painful process. This is because cloud infrastructure often requires not just the definition of the resources and themselves, but also the Identity and Access Management (IAM) policies that should be attached to these resources for optimal security. Both the resources and their required IAM policies also come with an almost infinite amount of possible configurations which increases the complexity.\nThis is where the AWS Cloud Development Kit comes in. It is an open-source software development framework for defining cloud infrastructure as code. Developers can use their favorite modern programming language, (TypeScript, JavaScript, Python, Java, C#/. Net,) to setup their cloud infrastructure. The code they write will then be synthesized into a CloudFormation template.\nThe beauty of the CDK lies in the fact that developers do not have to write all the text defining their infrastructure themselves. Instead, by using the object oriented abstractions and high level constructs the CDK provides, they can define their desired infrastructure and have the CDK generate the template. In other words, with the CDK, you can generate a 1000 lines long AWS CloudFormation template that deploys 50 AWS resources with about 20 lines of code! In addition, the constructs the CDK provides come with sane and sensible defaults which mean that developers can rest easy in the knowledge that their infrastructure has at least the minimum level of security.\nDue to all the attendant benefits, we shall be using the CDK to define our CI/CD pipeline. In particular, we will begin by using the CDK Pipelines construct. CDK Pipelines is a an opinionated construct that comes with some pre-defined stages which correspond to logical phases of deployment. It does however let you add more stages to it based on the needs of their application. CDK Pipelines is also self-mutating. This means that after the initial deploy, the pipeline automatically updates itself if you add new cloud infrastructure or pipeline stages in the source code. This means that we can start building our application with a minimal set of cloud resources and only add more resources as needed.\n\nLiking the series? In our next post, we will build our initial CI/CD pipeline using the AWS Cloud Development Kit (CDK). You can find the previous post here And if you’d like to dive into the code, here is a link to the project on GitHub."
  },
  {
    "objectID": "posts/2020-10-09-venv-in-vscode-integrated-terminal.html",
    "href": "posts/2020-10-09-venv-in-vscode-integrated-terminal.html",
    "title": "mbuotidem.github.io",
    "section": "",
    "text": "When you choose to use a python venv virtual environment in vscode, you might run into the error below :\nThe file C:\\yourpath\\.env\\Scripts\\Activate.ps1 is not digitally signed. You cannot run this script on the current system.\n{:class=“img-responsive”}\nA quick solution is to add this to your vscode settings.json{:class=“lnk”} file :\n{\n    \"terminal.integrated.shellArgs.windows\": [\n        \"-ExecutionPolicy\",\n        \"Bypass\"\n    ],\n\n}\nYou should restart your vscode and you’ll know you succeeded if you see the popup shown in the image below. Click allow and restart vscode again and you should be able to start your venv virtual environment without issues.\n{:class=“img-responsive”}\nCredit : https://stackoverflow.com/a/56199112{:class=“lnk”}"
  },
  {
    "objectID": "posts/2020-12-24-record-audio-in-blazor-using-mediarecorder-api-and-recorderjs.html",
    "href": "posts/2020-12-24-record-audio-in-blazor-using-mediarecorder-api-and-recorderjs.html",
    "title": "mbuotidem.github.io",
    "section": "",
    "text": "I recently started playing with Blazor and I decided to build an app that needed to get audio recorded from the users microphone via the browser. This post explains how I did that on Server Side Blazor.\nI decided to go with using the browser’s MediaDevices interface in conjunction with Matt Diamond’s aptly named Recorder.js library. Although Recorder.js is no longer actively maintained, it still works and more importantly, lets me record in .wav format which was part of my requirement.\nSo how does all of this work in the context of a Blazor application? My approach boils down to the following: 1. Record the audio from the user’s browser using JavaScript 2. Post the recorded audio blob to an API endpoint on my Blazor Server App using XMLHttpRequest and FormData. 3. Save the audio blob to a file on disk."
  },
  {
    "objectID": "posts/2020-12-24-record-audio-in-blazor-using-mediarecorder-api-and-recorderjs.html#record-the-audio-from-the-users-browser-using-javascript-and-recorder.js",
    "href": "posts/2020-12-24-record-audio-in-blazor-using-mediarecorder-api-and-recorderjs.html#record-the-audio-from-the-users-browser-using-javascript-and-recorder.js",
    "title": "mbuotidem.github.io",
    "section": "Record the audio from the user’s browser using JavaScript and Recorder.js",
    "text": "Record the audio from the user’s browser using JavaScript and Recorder.js\nAs mentioned earlier, I’ll be using the MediaDevices API along with Recorder.js to record the audio from the browser. The MediaDevices API has a method, getUserMedia() which enables recording of all sorts of media streams - audio, video, screen share etc. In our case, we will be using just the audio recording capability via Recorder.js. More on this in a second.\n\nThe user interface\nThe UI for the audio recording is lifted straight from the web dictaphone sample.\n{:class=“img-responsive”}\nAs the image above shows, we have a record and stop button along with an HTML5 canvas that visualizes the audio stream being heard by the microphone. Credit for the visualizer code goes to Soledad Penades.\nHere is the Blazor component code for the UI above. I simply replaced the code that was in Index.razor but feel free to create and use a different component.\n@page \"/\"\n@inject IJSRuntime jsRuntime\n\n<div class=\"wrapper mt-5\">\n    <section class=\"main-controls\">\n        <canvas id=\"canvas\" class=\"visualizer\" height=\"60\"></canvas>\n        <div id=\"buttons\">\n            <button class=\"@recordButton\" disabled=\"@Recording\" @onclick=Record>Record</button>\n            <button class=\"stop\" disabled=\"@NotRecording\" @onclick=Stop>Stop</button>\n        </div>\n    </section>\n\n    <section class=\"sound-clips\">\n    </section>\n    <audio controls autoplay>\n    </audio>\n</div>\n\n\n@code{\n    string recordButton = \"record\";\n\n    bool recording = false;\n    bool notRecording = true;\n\n\n    private async Task Record()\n    {\n\n        recordButton = \"recording\";\n        recording = true;\n        notRecording = false;\n        await jsRuntime.InvokeVoidAsync(\"MyJSMethods.startRecording\");\n    }\n\n    private async Task Stop()\n    {\n        recordButton = \"record\";\n        recording = false;\n        notRecording = true;\n        await jsRuntime.InvokeVoidAsync(\"MyJSMethods.stopRecording\");\n    }\n\n}\nThe field recordButton toggles the class of the record button from ‘record’ to ‘recording’. We use this to change the record button’s color to red when a recording is in progress and back to blue when recording is stopped.\nThe fields ‘recording’ and ‘notRecording’ are boolean, and are used to enable and disable clicking on the record and stop buttons depending on if a recording is in progress.\nThe component’s methods are pretty simple. Record toggles our CSS property fields and then calls out to a JavaScript function startRecording via the IJSRuntime service that enables Blazor’s JavaScript interoperability. Stop toggles back the CSS fields and then calls the JavaScript function stopRecording to, well, stop recording.\nBelow is the CSS for the component which I placed in site.css.\n#buttons {\n    display: flex;\n    flex-direction: row;\n    justify-content: space-between;\n}\n\n    #buttons button {\n        font-size: 1rem;\n        padding: 1rem;\n        width: calc(50% - 0.25rem);\n    }\n\n\n.record {\n    background: #0088cc;\n    text-align: center;\n    color: white;\n}\n\n    .record:hover, .record:focus {\n        box-shadow: inset 0px 0px 10px rgba(255, 255, 255, 1);\n        background: #0ae;\n    }\n\n    .record:active {\n        box-shadow: inset 0px 0px 20px rgba(0,0,0,0.5);\n        transform: translateY(2px);\n    }\n\n.recording {\n    background: red;\n    text-align: center;\n    color: white;\n}\n\n.stop {\n    font-size: 1rem;\n    background: #0088cc;\n    text-align: center;\n    color: white;\n    border: none;\n    transition: all 0.2s;\n    padding: 0.5rem;\n}\n\n    .stop:hover, .stop:focus {\n        box-shadow: inset 0px 0px 10px rgba(255, 255, 255, 1);\n        background: #0ae;\n    }\n\n    .stop:active {\n        box-shadow: inset 0px 0px 20px rgba(0,0,0,0.5);\n        transform: translateY(2px);\n    }\n\n\nNow that we understand how our Blazor component works, lets talk about the JavaScript part.\n\n\nThe JavaScript - getUserMedia and Recorder.js\nOur first step is to add a link to Recorder.js in our _Host.cshtml page, right below the link to the Blazor server framework script. We also include an empty <script> tag that will contain our JavaScript.\n<script src=\"_framework/blazor.server.js\"></script>\n<script src=\"https://cdn.rawgit.com/mattdiamond/Recorderjs/08e7abd9/dist/recorder.js\"></script>\n<script>\n  \n</script>\n\nNext, we can start writing the JavaScript we need to record audio. Let’s start with the functions that are called from C#. Note that the rest of the JavaScript code in this post should be placed within the empty <script> tag above.\nwindow.MyJSMethods = {\n\n    startRecording: function () {\n        navigator.getUserMedia({ audio: true }, onSuccess, onError);\n    },\n\n    stopRecording: function (element) {\n        stop.click();\n    },\n}\n\nstartRecording above invokes the browser’s getUserMedia method which prompts the user to grant us access to their microphone in order to start recording audio. If that request succeeds, then we invoke the onSuccess method which is where the actual recording takes place. If the user refuses to grant us access, then we call onError. The nice thing about the way this works is that the user is prompted to grant access only once - the browser will remember that access was granted on subsequent visits to your page. Lets look at onError.\nlet onError = function (err) {\n    console.log('The following error occurred: ' + err);\n};\n\nonError simply logs the error to the console. This was fine by me during development but is not very useful for the end user. Consider improving this to issue an alert and tell the user “Hey, you need to grant us access to your microphone if you want us to record your audio!”. Next up, onSuccess, where the recording magic happens!\nlet stop = document.querySelector('.stop');\n\nlet onSuccess = function (stream) {\n    let recorder;\n    let context;\n    let audio = document.querySelector('audio');\n    stop.disabled = false;\n\n    let mainSection = document.querySelector('.main-controls');\n    const canvas = document.querySelector('.visualizer');\n    canvas.width = mainSection.offsetWidth;\n\n    const canvasCtx = canvas.getContext(\"2d\");\n\n    context = new AudioContext();\n    let mediaStreamSource = context.createMediaStreamSource(stream);\n    recorder = new Recorder(mediaStreamSource);\n    recorder.record();\n\n    //visualize(stream, canvas, canvasCtx);\n\n\n    stop.onclick = function () {\n        recorder.stop();\n        \n        recorder.exportWAV(function (s) {\n            wav = window.URL.createObjectURL(s);\n            audio.src = window.URL.createObjectURL(s);\n            let filename = new Date().toISOString().replaceAll(':', \"\");\n            let fd = new FormData();\n            fd.append(\"file\", s, filename);\n            let xhr = new XMLHttpRequest();\n            xhr.addEventListener(\"load\", transferComplete);\n            xhr.addEventListener(\"error\", transferFailed)\n            xhr.addEventListener(\"abort\", transferFailed)\n            xhr.open(\"POST\", \"api/SaveAudio/Save/\", true);\n            xhr.send(fd);\n\n        });\n\n        stop.disabled = true;\n\n\n        function transferComplete(evt) {\n            console.log(\"The transfer is complete.\");\n            //GLOBAL.DotNetReference.invokeMethodAsync('Recognize', filename);\n\n        }\n\n        function transferFailed(evt) {\n            console.log(\"An error occurred while transferring the file.\");\n\n            console.log(evt.responseText);\n            console.log(evt.status);\n        }\n\n    }\n}\n\nonSuccess is called from getUserMedia which passes it a stream of the audio source. We then create the recorder, context, and audio variables. The API for Recorder.js is intuitive - to record, you call the record method on a Recorder object. A Recorder object takes a source and an optional config as parameters. In our case, we are using the browser’s AudioContext interface as our source. AudioContext processes the stream into an audio source that our Recorder instance can use when we invoke its record method. The audio variable just holds a reference to the HTML5 audio element through which we will play back the recorded audio to the user.\nWe also created two canvas related variables, canvas and canvasCtx, which we pass into a commented out call to the visualize function. This function handles the visualization of the audio stream and is not required for the recording to work. Ignore it for now - we will circle back to it.\nNext is our stopping mechanism. Outside onSuccess, we have a handle on the stop button. To stop recording, we attach a function to the stop button’s onclick event which does a couple of things. First, it stops the recording and then uses Recorder.js’s exportWAV method to export the audio blob as a .wav file. When the file is ready, we create a filename based on the timestamp. We set this file as the source for our HTML5 audio element to allow for immediate playback of the recorded audio. Then we post the audio file to our backend via XMLHttpRequest.\nBefore we discuss how the file is posted to our backend, a quick word about the functions transferComplete and transferFailed. You can do whatever you want to based on the status of the transfer of the file via XMLHttpRequest by attaching event listeners to it. For example, in the actual application I was building, on a successful POST, I invoked a C# method, in the commented out line reproduced below:\n//GLOBAL.DotNetReference.invokeMethodAsync('Recognize', filename);\n\nThis line triggered a method called Recognize in that version of my Blazor Component to perform speech recognition on the recorded audio file. To learn more about calling C# code from JavaScript via the Blazor JavaScript interop, see here and here."
  },
  {
    "objectID": "posts/2020-12-24-record-audio-in-blazor-using-mediarecorder-api-and-recorderjs.html#post-the-recorded-audio-blob-to-an-api-endpoint-on-my-blazor-server-app-using-xmlhttprequest-and-formdata",
    "href": "posts/2020-12-24-record-audio-in-blazor-using-mediarecorder-api-and-recorderjs.html#post-the-recorded-audio-blob-to-an-api-endpoint-on-my-blazor-server-app-using-xmlhttprequest-and-formdata",
    "title": "mbuotidem.github.io",
    "section": "Post the recorded audio blob to an API endpoint on my Blazor Server App using XMLHttpRequest and FormData",
    "text": "Post the recorded audio blob to an API endpoint on my Blazor Server App using XMLHttpRequest and FormData\nPosting the audio blob is fairly straight forward. As mentioned earlier, we use the XMLHttpRequest and FormData objects. Here’s that portion of the onSuccess function again:\nrecorder.exportWAV(function (s) {\n    wav = window.URL.createObjectURL(s);\n    audio.src = window.URL.createObjectURL(s);\n    let filename = new Date().toISOString().replaceAll(':', \"\");\n    let fd = new FormData();\n    fd.append(\"file\", s, filename);\n    let xhr = new XMLHttpRequest();\n    xhr.addEventListener(\"load\", transferComplete);\n    xhr.addEventListener(\"error\", transferFailed)\n    xhr.addEventListener(\"abort\", transferFailed)\n    xhr.open(\"POST\", \"api/SaveAudio/Save/\", true);\n    xhr.send(fd);\n});\n\nFirst we create the FormData object and then use its append method to add the filename we created as well as the recorded .wav file, here represented by s, to the form. Then we create the XMLHttpRequest object and attach event listeners for a successful transfer, as indicated by load, as well as for failures such as error and abort.\nNext, we initialize a POST request with XMLHttpRequest’s open method, indicating the API endpoint url api/SaveAudio/Save as the target. And then we invoke the send method, performing the actual POST request with the FormData object containing our audio blob file as its payload. Note that if your API is on a different domain, you might need to take steps to resolve CORS issues.\n\nSetup required to create the .NET Web API endpoint\nTo add an API endpoint to our Blazor Server application, we need to make some changes to the Startup.cs class. Add the using statement for .Net Core MVC to the list of using statements.\nusing Microsoft.AspNetCore.Mvc;\n\nThen modify the ConfigureServices method, adding the Mvc service:\npublic void ConfigureServices(IServiceCollection services)\n{\n    services.AddMvc(options => options.EnableEndpointRouting = false).SetCompatibilityVersion(CompatibilityVersion.Latest);\n    ...\n}\nNext, add app.UseMvcWithDefaultRoute(); to the Configure method. I placed it right after app.UseRouting() and before app.UseEndpoints();\npublic void Configure(IApplicationBuilder app, IWebHostEnvironment env)\n    {\n        ...\n        app.UseRouting();\n        \n        app.UseMvcWithDefaultRoute();\n\n\n        app.UseEndpoints(endpoints =>\n        {\n            endpoints.MapControllers();\n            endpoints.MapBlazorHub();\n            endpoints.MapFallbackToPage(\"/_Host\");\n        });\n    }\nWith this setup in place, we can now create our API controller class."
  },
  {
    "objectID": "posts/2020-12-24-record-audio-in-blazor-using-mediarecorder-api-and-recorderjs.html#save-the-audio-blob-to-a-file-on-disk.",
    "href": "posts/2020-12-24-record-audio-in-blazor-using-mediarecorder-api-and-recorderjs.html#save-the-audio-blob-to-a-file-on-disk.",
    "title": "mbuotidem.github.io",
    "section": "Save the audio blob to a file on disk.",
    "text": "Save the audio blob to a file on disk.\nTo receive the audio, we will be creating an ASP.NET Core Controller with a method Save. The class itself is called SaveAudio. Together, these map to the the API endpoint api/SaveAudio/Save which we used earlier in the JavaScript code. To add this route to our controller, we use the attribute route [Route(\"api/[controller]/Save\")]. Below is the code.\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Mvc;\nusing System.IO;\nusing System.Threading.Tasks;\n\n\nnamespace BlazorAudioRecorder\n{\n    public class SaveAudio: Controller\n    {\n        Microsoft.AspNetCore.Hosting.IWebHostEnvironment _hostingEnvironment;\n\n        public SaveAudio(Microsoft.AspNetCore.Hosting.IWebHostEnvironment hostingEnvironment)\n        {\n            _hostingEnvironment = hostingEnvironment;\n\n        }\n\n        [Route(\"api/[controller]/Save\")]\n        [HttpPost]\n        public async Task<IActionResult> Save(IFormFile file)\n        {\n            if (file.ContentType != \"audio/wav\")\n            {\n                return BadRequest(\"Wrong file type\");\n            }\n            var uploads = Path.Combine(_hostingEnvironment.WebRootPath, \"uploads\");\n            \n            var filePath = Path.Combine(uploads, file.FileName + \".wav\");\n            using (var fileStream = new FileStream(filePath, FileMode.Create))\n            {\n                await file.CopyToAsync(fileStream);\n            }\n            return Ok(\"File uploaded successfully\");\n        }\n    }\n}\n\nThe Save method will be invoked when an HttpPost request is made to the endpoint api/SaveAudio/Save. Notice that the name of the IFormFile parameter is file which corresponds to the name we gave the audio blob when creating our FormData object earlier. Here is that specific line of JavaScript code again:\nfd.append(\"file\", s, filename);\n\nBy doing this, we can rely on ASP.NET model binding magic to match everything up for us. The rest of the code is fairly simple, we check if the content type matches our expectation of audio/wav. If it doesn’t, we reject it, but if does, we go ahead and save the file to the uploads folder. You must create a folder named uploads in the wwwroot folder of your application, otherwise, your code will throw an exception since the destination you’re asking it to save to doesn’t exist.\nAnd there we have it! Compile, run, and record away! You can access the recorded files by visiting the wwwroot/uploads folder of your Blazor application.\n\nVisualizing  the audio stream\nHere is the code snippet for visualizing the audio stream. Add it to your _Host.cshtml file.\nlet audioCtx;\n\n// This function visualizes the audio stream coming out of the user's microphone.\n// Credit: Soledad Penades of https://soledadpenades.com/ via https://mdn.github.io/web-dictaphone/\n\nfunction visualize(stream, canvas, canvasCtx) {\n    if (!audioCtx) {\n        audioCtx = new AudioContext();\n    }\n\n    const source = audioCtx.createMediaStreamSource(stream);\n\n    const analyser = audioCtx.createAnalyser();\n    analyser.fftSize = 2048;\n    const bufferLength = analyser.frequencyBinCount;\n    const dataArray = new Uint8Array(bufferLength);\n\n    source.connect(analyser);\n    //analyser.connect(audioCtx.destination);\n\n    draw()\n\n    function draw() {\n        const WIDTH = canvas.width\n        const HEIGHT = canvas.height;\n\n        requestAnimationFrame(draw);\n\n        analyser.getByteTimeDomainData(dataArray);\n\n        canvasCtx.fillStyle = 'rgb(200, 200, 200)';\n        canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);\n\n        canvasCtx.lineWidth = 2;\n        canvasCtx.strokeStyle = 'rgb(0, 0, 0)';\n\n        canvasCtx.beginPath();\n\n        let sliceWidth = WIDTH * 1.0 / bufferLength;\n        let x = 0;\n\n\n        for (let i = 0; i < bufferLength; i++) {\n\n            let v = dataArray[i] / 128.0;\n            let y = v * HEIGHT / 2;\n\n            if (i === 0) {\n                canvasCtx.moveTo(x, y);\n            } else {\n                canvasCtx.lineTo(x, y);\n            }\n\n            x += sliceWidth;\n        }\n\n        canvasCtx.lineTo(canvas.width, canvas.height / 2);\n        canvasCtx.stroke();\n\n    }\n}\n\nThen make sure to uncomment\n//visualize(stream, canvas, canvasCtx);\n\nin the onSuccess method. When you click record, you should now see a visualization of the audio stream.     ### Github Source BlazorAudioRecorder     ### Further Reading\nhttps://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\nhttps://blog.addpipe.com/using-recorder-js-to-capture-wav-audio-in-your-html5-web-site/\nhttps://github.com/GersonRosales/Record-Audios-and-Videos-with-getUserMedia\nhttps://developer.mozilla.org/en-US/docs/Web/API/MediaStream_Recording_API/Using_the_MediaStream_Recording_API\nhttps://hacks.mozilla.org/2016/04/record-almost-everything-in-the-browser-with-mediarecorder/\nhttps://mdn.github.io/web-dictaphone/\nhttps://khalidabuhakmeh.com/upload-a-file-using-aspdotnet-core"
  },
  {
    "objectID": "posts/2020-02-20-test.html",
    "href": "posts/2020-02-20-test.html",
    "title": "Fastpages Notebook Blog Post",
    "section": "",
    "text": "This notebook is a demonstration of some of capabilities of fastpages with notebooks.\nWith fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts!\n\n\nThe first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this:\n# \"My Title\"\n> \"Awesome summary\"\n\n- toc: true\n- branch: master\n- badges: true\n- comments: true\n- author: Hamel Husain & Jeremy Howard\n- categories: [fastpages, jupyter]\n\nSetting toc: true will automatically generate a table of contents\nSetting badges: true will automatically include GitHub and Google Colab links to your notebook.\nSetting comments: true will enable commenting on your blog post, powered by utterances.\n\nThe title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README.\n\n\n\nA #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post.\nA #hide_input comment at the top of any code cell will only hide the input of that cell.\n\n\nThe comment #hide_input was used to hide the code that produced this.\n\n\nput a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it:\n\n\nCode\nimport pandas as pd\nimport altair as alt\n\n\nput a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it:\n\n\nCode\ncars = 'https://vega.github.io/vega-datasets/data/cars.json'\nmovies = 'https://vega.github.io/vega-datasets/data/movies.json'\nsp500 = 'https://vega.github.io/vega-datasets/data/sp500.csv'\nstocks = 'https://vega.github.io/vega-datasets/data/stocks.csv'\nflights = 'https://vega.github.io/vega-datasets/data/flights-5k.json'\n\n\nplace a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it:\n\n#collapse-output\nprint('The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.')\n\nThe comment #collapse-output was used to collapse the output of this cell by default but you can expand it.\n\n\n\n\n\nCharts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook.\n\n\n\n# single-value selection over [Major_Genre, MPAA_Rating] pairs\n# use specific hard-wired values as the initial selected values\nselection = alt.selection_single(\n    name='Select',\n    fields=['Major_Genre', 'MPAA_Rating'],\n    init={'Major_Genre': 'Drama', 'MPAA_Rating': 'R'},\n    bind={'Major_Genre': alt.binding_select(options=genres), 'MPAA_Rating': alt.binding_radio(options=mpaa)}\n)\n  \n# scatter plot, modify opacity based on selection\nalt.Chart(df).mark_circle().add_selection(\n    selection\n).encode(\n    x='Rotten_Tomatoes_Rating:Q',\n    y='IMDB_Rating:Q',\n    tooltip='Title:N',\n    opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05))\n)\n\n\n\n\n\n\n\n\n\n\n\nalt.Chart(df).mark_circle().add_selection(\n    alt.selection_interval(bind='scales', encodings=['x'])\n).encode(\n    alt.X('Rotten_Tomatoes_Rating', type='quantitative'),\n    alt.Y('IMDB_Rating', type='quantitative', axis=alt.Axis(minExtent=30)),\n#     y=alt.Y('IMDB_Rating:Q', ), # use min extent to stabilize axis title placement\n    tooltip=['Title:N', 'Release_Date:N', 'IMDB_Rating:Q', 'Rotten_Tomatoes_Rating:Q']\n).properties(\n    width=500,\n    height=400\n)\n\n\n\n\n\n\n\n\n\n\n\n# select a point for which to provide details-on-demand\nlabel = alt.selection_single(\n    encodings=['x'], # limit selection to x-axis value\n    on='mouseover',  # select on mouseover events\n    nearest=True,    # select data point nearest the cursor\n    empty='none'     # empty selection includes no data points\n)\n\n# define our base line chart of stock prices\nbase = alt.Chart().mark_line().encode(\n    alt.X('date:T'),\n    alt.Y('price:Q', scale=alt.Scale(type='log')),\n    alt.Color('symbol:N')\n)\n\nalt.layer(\n    base, # base line chart\n    \n    # add a rule mark to serve as a guide line\n    alt.Chart().mark_rule(color='#aaa').encode(\n        x='date:T'\n    ).transform_filter(label),\n    \n    # add circle marks for selected time points, hide unselected points\n    base.mark_circle().encode(\n        opacity=alt.condition(label, alt.value(1), alt.value(0))\n    ).add_selection(label),\n\n    # add white stroked text to provide a legible background for labels\n    base.mark_text(align='left', dx=5, dy=-5, stroke='white', strokeWidth=2).encode(\n        text='price:Q'\n    ).transform_filter(label),\n\n    # add text labels for stock prices\n    base.mark_text(align='left', dx=5, dy=-5).encode(\n        text='price:Q'\n    ).transform_filter(label),\n    \n    data=stocks\n).properties(\n    width=500,\n    height=400\n)\n\n\n\n\n\n\n\n\n\n\nYou can display tables per the usual way in your blog:\n\n# display table with pandas\ndf[['Title', 'Worldwide_Gross', \n    'Production_Budget', 'Distributor', 'MPAA_Rating', 'IMDB_Rating', 'Rotten_Tomatoes_Rating']].head()\n\n\n\n\n\n  \n    \n      \n      Title\n      Worldwide_Gross\n      Production_Budget\n      Distributor\n      MPAA_Rating\n      IMDB_Rating\n      Rotten_Tomatoes_Rating\n    \n  \n  \n    \n      0\n      The Land Girls\n      146083.0\n      8000000.0\n      Gramercy\n      R\n      6.1\n      NaN\n    \n    \n      1\n      First Love, Last Rites\n      10876.0\n      300000.0\n      Strand\n      R\n      6.9\n      NaN\n    \n    \n      2\n      I Married a Strange Person\n      203134.0\n      250000.0\n      Lionsgate\n      None\n      6.8\n      NaN\n    \n    \n      3\n      Let's Talk About Sex\n      373615.0\n      300000.0\n      Fine Line\n      None\n      NaN\n      13.0\n    \n    \n      4\n      Slam\n      1087521.0\n      1000000.0\n      Trimark\n      R\n      3.4\n      62.0\n    \n  \n\n\n\n\n\n\n\n\n\nYou can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax:\n![](my_icons/fastai_logo.png)\n\n\n\n\nRemote images can be included with the following markdown syntax:\n![](https://image.flaticon.com/icons/svg/36/36686.svg)\n\n\n\n\nAnimated Gifs work, too!\n![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif)\n\n\n\n\nYou can include captions with markdown images like this:\n![](https://www.fast.ai/images/fastai_paper/show_batch.png \"Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/\")"
  },
  {
    "objectID": "posts/2020-02-20-test.html#github-flavored-emojis",
    "href": "posts/2020-02-20-test.html#github-flavored-emojis",
    "title": "Fastpages Notebook Blog Post",
    "section": "GitHub Flavored Emojis",
    "text": "GitHub Flavored Emojis\nTyping I give this post two :+1:! will render this:\nI give this post two :+1:!"
  },
  {
    "objectID": "posts/2020-02-20-test.html#tweetcards",
    "href": "posts/2020-02-20-test.html#tweetcards",
    "title": "Fastpages Notebook Blog Post",
    "section": "Tweetcards",
    "text": "Tweetcards\nTyping > twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this:\n\ntwitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20"
  },
  {
    "objectID": "posts/2020-02-20-test.html#youtube-videos",
    "href": "posts/2020-02-20-test.html#youtube-videos",
    "title": "Fastpages Notebook Blog Post",
    "section": "Youtube Videos",
    "text": "Youtube Videos\nTyping > youtube: https://youtu.be/XfoYk_Z5AkI will render this:"
  },
  {
    "objectID": "posts/2020-02-20-test.html#boxes-callouts",
    "href": "posts/2020-02-20-test.html#boxes-callouts",
    "title": "Fastpages Notebook Blog Post",
    "section": "Boxes / Callouts",
    "text": "Boxes / Callouts\nTyping > Warning: There will be no second warning! will render this:\n\n\n\n\n\n\nWarning\n\n\n\nThere will be no second warning!\n\n\nTyping > Important: Pay attention! It's important. will render this:\n\n\n\n\n\n\nImportant\n\n\n\nPay attention! It’s important.\n\n\nTyping > Tip: This is my tip. will render this:\n\n\n\n\n\n\nTip\n\n\n\nThis is my tip.\n\n\nTyping > Note: Take note of this. will render this:\n\n\n\n\n\n\nNote\n\n\n\nTake note of this.\n\n\nTyping > Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs:\n\n\n\n\n\n\nNote\n\n\n\nA doc link to an example website: fast.ai should also work fine."
  },
  {
    "objectID": "posts/2020-02-20-test.html#footnotes",
    "href": "posts/2020-02-20-test.html#footnotes",
    "title": "Fastpages Notebook Blog Post",
    "section": "Footnotes",
    "text": "Footnotes\nYou can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this:\n{% raw %}For example, here is a footnote {% fn 1 %}.\nAnd another {% fn 2 %}\n{{ 'This is the footnote.' | fndetail: 1 }}\n{{ 'This is the other footnote. You can even have a [link](www.github.com)!' | fndetail: 2 }}{% endraw %}\nFor example, here is a footnote {% fn 1 %}.\nAnd another {% fn 2 %}\n{{ ‘This is the footnote.’ | fndetail: 1 }} {{ ‘This is the other footnote. You can even have a link!’ | fndetail: 2 }}"
  },
  {
    "objectID": "posts/2020-01-14-test-markdown-post.html",
    "href": "posts/2020-01-14-test-markdown-post.html",
    "title": "An Example Markdown Post",
    "section": "",
    "text": "Jekyll requires blog post files to be named according to the following format:\nYEAR-MONTH-DAY-filename.md\nWhere YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files.\nThe first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above.\n\n\n\nYou can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule:\n\n\n\n\nHere’s a list:\n\nitem 1\nitem 2\n\nAnd a numbered list:\n\nitem 1\nitem 2\n\n\n\n\n\nThis is a quotation\n\n{% include alert.html text=“You can include alert boxes” %}\n…and…\n{% include info.html text=“You can include info boxes” %}\n\n\n\n\n\n\n\nYou can format text and code per usual\nGeneral preformatted text:\n# Do a thing\ndo_thing()\nPython code and output:\n# Prints '2'\nprint(1+1)\n2\nFormatting text as shell commands:\necho \"hello world\"\n./some_script.sh --option \"value\"\nwget https://example.com/cat_photo1.png\nFormatting text as YAML:\nkey: value\n- another_key: \"another value\"\n\n\n\n\n\n\nColumn 1\nColumn 2\n\n\n\n\nA thing\nAnother thing\n\n\n\n\n\n\n{% twitter https://twitter.com/jakevdp/status/1204765621767901185?s=20 %}"
  },
  {
    "objectID": "posts/2021-04-24-building-a-modern-web-application-using-aws-cdk-part-3.html",
    "href": "posts/2021-04-24-building-a-modern-web-application-using-aws-cdk-part-3.html",
    "title": "Part 3 - Guichet - Building the application’s resources",
    "section": "",
    "text": "In our last post we built out the CI/CD pipeline stack along with tests to verify that it works. In this post, we shall build out some of the cloud resources our application needs. Our application works like this: an audio file is uploaded to an S3 bucket. That upload triggers a lambda function which calls the Amazon Transcribe service, sending it the audio file that was just uploaded. The lambda will then store the transcription result in a DynamoDB table. We will continue using the AWS CDK infrastructure as code approach to add the S3 bucket and DynamoDB table to our application stack. We will also update our application’s lambda function with necessary access permissions for the bucket, the DynamoDB table, and the Amazon Transcribe service. Let’s get started.\n\nThe S3 bucket\nCreating an S3 bucket resource is simple with the AWS CDK. The same general pattern applies regardless of the construct. All you need do is import the module that contains said construct, and then make use of it. In this case, we need the s3 construct which we can find in the npm module @aws-cdk/aws-s3. We create a bucket and set some of its properties such as the removal policy and the access permissions. You can learn more about the available bucket property options here. Finally, we use the CfnOutput construct to surface the name of the created bucket upon completion.\nimport * as cdk from '@aws-cdk/core';\nimport * as s3 from '@aws-cdk/aws-s3';\n\n//s3 audio bucket\nconst audioBucket = new s3.Bucket(this, 'AudioBucket', {\n    removalPolicy: cdk.RemovalPolicy.DESTROY,\n    publicReadAccess: true,\n    accessControl: s3.BucketAccessControl.PUBLIC_READ,\n});\n\nnew cdk.CfnOutput(this, 'audioBucket', { value: audioBucket.bucketName });\n\n\nThe DynamoDB table\nNext up is our DynamoDB table. Once again, a high level construct for it exists in @aws-cdk/aws-dynamodb. In the code below, we use it to create our table and set its partition key. And once again, we use CfnOutput to output the name of the created table. You can learn more about the DynamoDB construct here.\nimport * as cdk from '@aws-cdk/core';\nimport * as dynamodb from '@aws-cdk/aws-dynamodb';\n\n//DynamoDB table for storing transcription results\nconst table = new dynamodb.Table(this, 'audioTranscriptions', {\n    partitionKey: { name: 'audio', type: dynamodb.AttributeType.STRING }\n});\n\nnew cdk.CfnOutput(this, 'ddbTable', { value: table.tableName });\n\n\nUpdating our Transcriber lambda’s resource definition\nOur lambda resource’s definition needs updating to account for the S3 bucket and DynamoDB table we’ve just created. Since we intend to communicate with these resources from within our lambda, we will need to know their names. In addition, we need to setup our lambda with the right permissions to access these resources. As usual, we pull in the module that contains the lambda construct, aws-cdk/aws-lambda. You can learn more about the lambda construct here.\nimport * as cdk from '@aws-cdk/core';\nimport * as lambda from '@aws-cdk/aws-lambda';\n\n//transcriber lambda\nconst transcriber = new lambda.Function(this, 'Transcriber', {\n  runtime: lambda.Runtime.NODEJS_10_X,\n  code: lambda.Code.fromAsset('lambda'),\n  handler: 'transcriber.handler',\n  timeout: Duration.seconds(300),\n  memorySize: 1024,\n  environment: {\n      \"TABLE_NAME\": table.tableName,\n      \"BUCKET_NAME\": audioBucket.bucketName,\n  },\n});\n\ntranscriber.addEventSource(new event_sources.S3EventSource(audioBucket, { events: [s3.EventType.OBJECT_CREATED] }));\n\naudioBucket.grantRead(transcriber);\n\ntable.grantWriteData(transcriber);\n\ntranscriber.addToRolePolicy(new iam.PolicyStatement({\n  effect: iam.Effect.ALLOW,\n  actions: ['transcribe:StartTranscriptionJob'],\n  resources: ['*'],\n}))\n\nIn the code above, we access the table and bucket names from their respective objects and add them as environment variables for our lambda function. That way, our lambda code will be able to access that information easily. Next, we setup our s3 bucket as an event source for our lambda in the line transcriber.addEventSource(new event_sources.S3EventSource(audioBucket, { events: [s3.EventType.OBJECT_CREATED] }));.\nIn the next two lines, we grant our lambda function the access permissions it needs to: - read from the bucket:audioBucket.grantRead(transcriber); and - write to the DynamoDB table: table.grantWriteData(transcriber);\nFinally, in the last four lines of the code snippet above, we create the IAM Policy that gives our lambda the permission to interact with the Amazon Transcribe service. To figure out what actions were required for the IAM Policy, we just needed to carefully study the AWS Documentation for the service. In this case, the relevant information was available in an aptly named document, How Amazon Transcribe works with IAM.\n\n\nTesting the application stack\nSince our infrastructure is code, we should also write tests for it. Fortunately, testing AWS CDK constructs is fairly easy. The CDK assert module comes with helpers that simplify testing CDK code. This module relies on the Jest test framework. In our test code, we check that our stack has the following resources : - a bucket to store audio files - a notifier that will call our lambda when something is uploaded to our bucket - a DynamoDB table to store transcriptions - a lambda function with the correct runtime - a lambda function with the correct environment variables - a lambda function with the correct permission and role policies to allow it to communicate with our S3 bucket, our DynamoDB table, and the Amazon Transcribe service\n\nimport '@aws-cdk/assert/jest';\nimport { App } from '@aws-cdk/core';\nimport { GuichetStack } from '../src/guichet';\nimport { ResourcePart } from '@aws-cdk/assert';\n\n\ndescribe('Create Guichet App Resources', () => {\n  describe('GuichetStack', () => {\n    const app = new App({ context: { '@aws-cdk/core:newStyleStackSynthesis': '1' } });\n\n    describe('has', () => {\n\n      let stack = new GuichetStack(app, 'test', {\n      });\n\n      test('audio bucket', () => {\n        expect(stack).toHaveResource('AWS::S3::Bucket', {\n          Properties: {\n            AccessControl: \"PublicRead\"\n          },\n          UpdateReplacePolicy: 'Delete',\n          DeletionPolicy: 'Delete',\n        }, ResourcePart.CompleteDefinition);\n\n      });\n\n      test('audio bucket with lambda notifier', () => {\n        expect(stack).toHaveResource('Custom::S3BucketNotifications', {\n          \"NotificationConfiguration\": {\n            \"LambdaFunctionConfigurations\": [\n              {\n                \"Events\": [\n                  \"s3:ObjectCreated:*\"\n                ],\n                \"LambdaFunctionArn\": {\n                  \"Fn::GetAtt\": [\n                    \"Transcriber4926E100\",\n                    \"Arn\"\n                  ]\n                }\n              }\n            ]\n          }\n        });\n\n      });\n\n\n      test('dynamodb table', () => {\n        expect(stack).toHaveResource(\"AWS::DynamoDB::Table\", {\n          AttributeDefinitions: [{ AttributeName: 'audio', AttributeType: 'S' }],\n        });\n\n      });\n\n      test('transcriber lambda function', () => {\n        expect(stack).toHaveResource('AWS::Lambda::Function', {\n          Runtime: 'nodejs10.x',\n\n        });\n      });\n\n      test('transcriber lambda function with env vars', () => {\n        expect(stack).toHaveResource(\"AWS::Lambda::Function\", {\n          Environment: {\n            Variables: {\n              TABLE_NAME: { \"Ref\": \"audioTranscriptions1A6D233C\" },\n              BUCKET_NAME: { \"Ref\": \"AudioBucket96BEECBA\" },\n            }\n          }\n        });\n      });\n\n      test('transcriber lambda has role permissions', () => {\n        expect(stack).toHaveResource(\"AWS::IAM::Policy\", {\n          PolicyDocument: {\n            Statement: [\n              {\n                Action: [\n                  \"s3:GetObject*\",\n                  \"s3:GetBucket*\",\n                  \"s3:List*\"\n                ],\n                Effect: 'Allow',\n                Resource: [\n                  {\n                    \"Fn::GetAtt\": [\n                      \"AudioBucket96BEECBA\",\n                      \"Arn\"\n                    ]\n                  },\n                  {\n                    \"Fn::Join\": [\n                      \"\",\n                      [\n                        {\n                          \"Fn::GetAtt\": [\n                            \"AudioBucket96BEECBA\",\n                            \"Arn\"\n                          ]\n                        },\n                        \"/*\"\n                      ]\n                    ]\n                  }\n                ],\n              },\n              {\n                \"Action\": [\n                  \"dynamodb:BatchWriteItem\",\n                  \"dynamodb:PutItem\",\n                  \"dynamodb:UpdateItem\",\n                  \"dynamodb:DeleteItem\"\n                ],\n                \"Effect\": \"Allow\",\n                \"Resource\": [\n                  {\n                    \"Fn::GetAtt\": [\n                      \"audioTranscriptions1A6D233C\",\n                      \"Arn\"\n                    ]\n                  },\n                  {\n                    \"Ref\": \"AWS::NoValue\"\n                  }\n                ]\n              },\n              {\n                \"Action\": \"transcribe:StartTranscriptionJob\",\n                \"Effect\": \"Allow\",\n                \"Resource\": \"*\"\n              }\n            ],\n            Version: '2012-10-17',\n          },\n          PolicyName: 'TranscriberServiceRoleDefaultPolicy45780372',\n          Roles: [\n            {\n              Ref: 'TranscriberServiceRole495F268B',\n            },\n          ],\n        });\n      });\n    });\n\n  });\n});\nAnd here’s our test run output:\n{:class=“img-responsive”}\n\nLiking the series? In our next post, we will continue building out our backend, modifying our lambda to make the calls to the Amazon Transcribe service. You can find the previous post here And if you’d like to dive into the code, here is a link to the project on GitHub."
  },
  {
    "objectID": "posts/2020-12-19-Error-connect-ENETUNREACH-169.254.169.254.80.html",
    "href": "posts/2020-12-19-Error-connect-ENETUNREACH-169.254.169.254.80.html",
    "title": "mbuotidem.github.io",
    "section": "",
    "text": "When you are using the AWS Node.js SDK, you might encouter the error message :\nUnhandledPromiseRejectionWarning: Error: connect ENETUNREACH 169.254.169.254:80 at TCPConnectWrap.afterConnect [as oncomplete] (net.js:1145:16).\n\n{:class=“img-responsive”}\n\n\nThis error is likely occuring because the AWS SDK is unable to find your AWS credentials. AWS Documentation has a list of ways you can load credentials in Node.js\n\nWhere the credential files are stored depends on your operating system.\n\non Linux, Unix, and macOS: ~/.aws/credentials\non Windows: C:\\Users\\USER_NAME\\.aws\\credentials\n\n\n\nIn my case, the issue was that I did not have a [default] profile in my aws credentials file. As such, I needed to tell the AWS Node.js SDK which profile to use instead.\nAssuming your profile is named `myspecial-profile, here’s how you can do that :\nconst AWS = require('aws-sdk');\nAWS.config.region = 'us-east-1';\nvar credentials = new AWS.SharedIniFileCredentials({profile: 'myspecial-profile'});\nAWS.config.credentials = credentials;\n\nLearn more about loading AWS credentials in Node.js from the shared credentials file{:class=“lnk”}."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Chasing DevOps Nirvana",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nJan 15, 2023\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nJan 12, 2023\n\n\nTristan O’Malley\n\n\n\n\n\n\n  \n\n\n\n\nElastic Beanstalk 502 Bad Gateway / 111 connection refused while connecting to upstream error on .net\n\n\n\n\n\nHow to resolve nginx 502 Bad Gateway / 111-connection-refused error due to .net web application start failure\n\n\n\n\n\n\nMay 28, 2021\n\n\nIsaac Mbuotidem\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPart 4 - Guichet - Building the transcription capability\n\n\n\n\n\nSeries on building a web application with the AWS CDK continued\n\n\n\n\n\n\nApr 25, 2021\n\n\nIsaac Mbuotidem\n\n\n\n\n\n\n  \n\n\n\n\nPart 3 - Guichet - Building the application’s resources\n\n\n\n\n\nSeries on building a web application with the AWS CDK continued\n\n\n\n\n\n\nApr 24, 2021\n\n\nIsaac Mbuotidem\n\n\n\n\n\n\n  \n\n\n\n\nPart 2 - Guichet - Building the CI/CD pipeline\n\n\n\n\n\nSeries on building a web application with the AWS CDK continued\n\n\n\n\n\n\nApr 23, 2021\n\n\nIsaac Mbuotidem\n\n\n\n\n\n\n  \n\n\n\n\nPart 1 - Guichet - CI/CD pipeline architecture\n\n\n\n\n\nSeries on building a web application with the AWS CDK continued\n\n\n\n\n\n\nApr 22, 2021\n\n\nIsaac Mbuotidem\n\n\n\n\n\n\n  \n\n\n\n\nPart 0 - Guichet - a cloud native web application built on AWS using the CDK\n\n\n\n\n\nFirst article in a series on building a serverless web application with the AWS CDK\n\n\n\n\n\n\nApr 18, 2021\n\n\nIsaac Mbuotidem\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 31, 2021\n\n\nIsaac Mbuotidem\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 20, 2021\n\n\nIsaac Mbuotidem\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 17, 2021\n\n\nIsaac Mbuotidem\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 9, 2021\n\n\nIsaac Mbuotidem\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJan 8, 2021\n\n\nIsaac Mbuotidem\n\n\n\n\n\n\n  \n\n\n\n\nRecord the audio from the user’s browser using JavaScript and Recorder.js\n\n\n\n\n\n\n\n\n\n\n\n\nDec 24, 2020\n\n\nIsaac Mbuotidem\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDec 19, 2020\n\n\nIsaac Mbuotidem\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 9, 2020\n\n\nIsaac Mbuotidem\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I’m a software engineer who loves working with cloud applications. In my current role, I am spending a lot of time in the AWS ecosystem building infrastructure as code, improving developer experience/productivity, and helping to promote a devops culture. In the past, I have worked with C#, the Microsoft stack, and Azure, doing everything from developing web applications to chatbots. I am most comfortable working in Python, C# and JavaScript on both AWS and Azure.\nPhilosophy\nI enjoy learning new technology and languages. I’ve always found that such playful exploration and continuous learning not only keeps my skills sharp but also is genuinely gratifying.\nInterests\nOn weekends, I can be found either showing off my salsa dance moves or making hard tackles on the soccer pitch."
  }
]